[ DataRobot docs ](../../../index.html "DataRobot docs")

  * [ Data ](../../../data/index.html) [ Data ](../../../data/index.html)
    * [ Data connections ](../../../data/connect-data/index.html) [ Data connections ](../../../data/connect-data/index.html)
      * [ Share secure configurations ](../../../data/connect-data/secure-config.html)
      * [ Data connections ](../../../data/connect-data/data-conn.html)
    * [ AI Catalog ](../../../data/ai-catalog/index.html) [ AI Catalog ](../../../data/ai-catalog/index.html)
      * [ Load data ](../../../data/ai-catalog/catalog.html)
      * [ Manage assets ](../../../data/ai-catalog/manage-asset.html)
      * [ Work with assets ](../../../data/ai-catalog/catalog-asset.html)
      * [ Schedule snapshots ](../../../data/ai-catalog/snapshot.html)
      * [ Prepare data with Spark SQL ](../../../data/ai-catalog/spark.html)
    * [ Import data ](../../../data/import-data/index.html) [ Import data ](../../../data/import-data/index.html)
      * [ Import to DataRobot directly ](../../../data/import-data/import-to-dr.html)
      * [ Large datasets ](../../../data/import-data/large-data/index.html) [ Large datasets ](../../../data/import-data/large-data/index.html)
        * [ Fast EDA for large datasets ](../../../data/import-data/large-data/fast-eda.html)
    * [ Transform data ](../../../data/transform-data/index.html) [ Transform data ](../../../data/transform-data/index.html)
      * [ Interaction-based transformations ](../../../data/transform-data/feature-disc.html)
      * [ Feature Discovery ](../../../data/transform-data/feature-discovery/index.html) [ Feature Discovery ](../../../data/transform-data/feature-discovery/index.html)
        * [ End-to-end Feature Discovery ](../../../data/transform-data/feature-discovery/enrich-data-using-feature-discovery.html)
        * [ Set up Feature Discovery projects ](../../../data/transform-data/feature-discovery/fd-overview.html)
        * [ Snowflake integration ](../../../data/transform-data/feature-discovery/fd-snowflake.html)
        * [ Feature Discovery settings ](../../../data/transform-data/feature-discovery/fd-adv-opt.html)
        * [ Time-aware feature engineering ](../../../data/transform-data/feature-discovery/fd-time.html)
        * [ Derived features ](../../../data/transform-data/feature-discovery/fd-gen.html)
        * [ Predictions ](../../../data/transform-data/feature-discovery/fd-predict.html)
      * [ Manual transformations ](../../../data/transform-data/feature-transforms.html)
    * [ Analyze data ](../../../data/analyze-data/index.html) [ Analyze data ](../../../data/analyze-data/index.html)
      * [ Assess data quality with EDA ](../../../data/analyze-data/assess-data-quality-eda.html)
      * [ Analyze features using histograms ](../../../data/analyze-data/analyze-histogram.html)
      * [ Analyze frequent values ](../../../data/analyze-data/analyze-frequent-values.html)
      * [ Feature details ](../../../data/analyze-data/histogram.html)
      * [ Exploratory Spatial Data Analysis (ESDA) ](../../../data/analyze-data/lai-esda.html)
      * [ Feature Associations ](../../../data/analyze-data/feature-assoc.html)
      * [ Use data pipelines for ingest and transformation ](../../../data/analyze-data/pipelines.html)
    * [ Data preview features ](../../../data/data-preview/index.html) [ Data preview features ](../../../data/data-preview/index.html)
      * [ Create feature lists in the Relationship Editor ](../../../data/data-preview/safer-rel-editor-feature-lists.html)
    * [ Data FAQ ](../../../data/data-faq.html)
  * [ Modeling ](../../index.html) [ Modeling ](../../index.html)
    * [ Build models ](../../build-models/index.html) [ Build models ](../../build-models/index.html)
      * [ Build models ](../../build-models/build-basic/index.html) [ Build models ](../../build-models/build-basic/index.html)
        * [ Basic model workflow ](../../build-models/build-basic/model-data.html)
        * [ Work with feature lists ](../../build-models/build-basic/feature-lists.html)
        * [ Unlock Holdout ](../../build-models/build-basic/unlocking-holdout.html)
        * [ Comprehensive Autopilot ](../../build-models/build-basic/more-accuracy.html)
        * [ Add/delete models ](../../build-models/build-basic/creating-addl-models.html)
        * [ Frozen runs ](../../build-models/build-basic/frozen-run.html)
        * [ Model Repository ](../../build-models/build-basic/repository.html)
      * [ Advanced options ](../../build-models/adv-opt/index.html) [ Advanced options ](../../build-models/adv-opt/index.html)
        * [ Additional ](../../build-models/adv-opt/additional.html)
        * [ Bias and Fairness ](../../build-models/adv-opt/fairness-metrics.html)
        * [ Clustering advanced options ](../../build-models/adv-opt/time-series-cluster-adv-opt.html)
        * [ External Predictions ](../../build-models/adv-opt/external-preds.html)
        * [ Feature Constraints ](../../build-models/adv-opt/feature-con.html)
        * [ Image Augmentation ](../../build-models/adv-opt/ttia.html)
        * [ Partitioning ](../../build-models/adv-opt/partitioning.html)
        * [ Smart Downsampling ](../../build-models/adv-opt/smart-ds.html)
        * [ Time series ](../../build-models/adv-opt/time-series-adv-opt.html)
        * [ GPUs for deep learning ](../../build-models/adv-opt/gpus.html)
    * [ Model insights ](../index.html) [ Model insights ](../index.html)
      * [ Evaluate ](../evaluate/index.html) [ Evaluate ](../evaluate/index.html)
        * [ Accuracy Over Space ](../../special-workflows/location-ai/lai-insights.html)
        * [ Accuracy Over Time ](../evaluate/aot.html)
        * [ Advanced Tuning ](../evaluate/adv-tuning.html)
        * [ Anomaly visualizations ](../evaluate/anom-viz.html)
        * [ Confusion Matrix (for multiclass models) ](../evaluate/multiclass.html)
        * [ Forecasting Accuracy ](../evaluate/forecast-acc.html)
        * [ Forecast vs Actual ](../evaluate/fore-act.html)
        * [ Lift Chart ](../evaluate/lift-chart.html)
        * [ Period Accuracy ](../evaluate/period-accuracy.html)
        * [ Residuals ](../evaluate/residuals.html)
        * [ ROC Curve tools ](../evaluate/roc-curve-tab/index.html) [ ROC Curve tools ](../evaluate/roc-curve-tab/index.html)
          * [ Use the ROC Curve tools ](../evaluate/roc-curve-tab/roc-curve-tab-use.html)
          * [ Select data and display threshold ](../evaluate/roc-curve-tab/threshold.html)
          * [ Confusion matrix ](../evaluate/roc-curve-tab/confusion-matrix.html)
          * [ Prediction Distribution graph ](../evaluate/roc-curve-tab/pred-dist-graph.html)
          * [ ROC curve ](../evaluate/roc-curve-tab/roc-curve.html)
          * [ Profit curve ](../evaluate/roc-curve-tab/profit-curve.html)
          * [ Cumulative Charts ](../evaluate/roc-curve-tab/cumulative-charts.html)
          * [ Custom charts ](../evaluate/roc-curve-tab/custom-charts.html)
          * [ Metrics ](../evaluate/roc-curve-tab/metrics.html)
        * [ Series Insights (clustering) ](../evaluate/series-insights.html)
        * [ Series Insights (multiseries) ](../evaluate/series-insights-multi.html)
        * [ Stability ](../evaluate/stability.html)
        * [ Training Dashboard ](../evaluate/training-dash.html)
      * [ Understand ](index.html) [ Understand ](index.html)
        * [ Cluster Insights ](cluster-insights.html)
        * [ Feature Effects ](feature-effects.html) [ Feature Effects ](feature-effects.html)

[For Self-Managed AI Platform users running v11.1, see the on-premise platform
documentation __](/11.1/en/docs/index.html)

Feature Effects

          * Display options 
            * Sort options 
            * Set the number of bins 
            * Select the partition fold 
            * Select the class (multiclass only) 
            * Export 
            * More options 
          * List of features 
          * Feature Effects results 
            * Target range (Y-axis) 
            * Feature values (X-axis) 
              * For numeric features 
              * Predicted/actual logic 
              * Partial dependence logic 
              * Chart-specific logic 
              * For categorical features 
            * Feature value tooltip 
            * Feature value count 
            * Display controls 
          * More info... 
            * Average value calculations 
            * Interpret the displays 
              * Training data as the viewing subset 
            * Partial dependence calculations 
            * Data selection for time-aware projects 
              * Calculate backtests 
              * Set the partition fold 
              * Interpret days as numerics 
            * Binning and top values 
            * How Exposure changes output 
            * How Weight changes output 

        * [ Feature Impact ](feature-impact.html)
        * [ Prediction Explanations ](pred-explain/index.html) [ Prediction Explanations ](pred-explain/index.html)
          * [ Prediction Explanations overview ](pred-explain/predex-overview.html)
          * [ SHAP Prediction Explanations ](pred-explain/shap-pe.html)
          * [ XEMP Prediction Explanations ](pred-explain/xemp-pe.html)
          * [ Text Prediction Explanations ](pred-explain/predex-text.html)
          * [ Prediction Explanations for clusters ](pred-explain/cluster-pe.html)
          * [ Prediction Explanations for time-aware projects ](pred-explain/ts-otv-predex.html)
        * [ Word Cloud ](word-cloud.html)
      * [ Describe ](../describe/index.html) [ Describe ](../describe/index.html)
        * [ Blueprint ](../describe/blueprints.html)
        * [ Blueprint JSON ](../describe/blueprint-json.html)
        * [ Coefficients (preprocessing) ](../describe/coefficients.html)
        * [ Constraints (monotonic) ](../describe/monotonic.html)
        * [ Data Quality Handling Report ](../describe/dq-report.html)
        * [ Eureqa Models ](../describe/eureqa.html)
        * [ Log ](../describe/log.html)
        * [ Model Info ](../describe/model-info.html)
        * [ Rating Tables ](../describe/rating-table.html)
        * [ GA2M output (from Rating Tables) ](../describe/ga2m.html)
      * [ Predict ](../predictions/index.html) [ Predict ](../predictions/index.html)
        * [ Deploy ](../predictions/deploy.html)
        * [ Downloads ](../predictions/download.html)
        * [ Make Predictions ](../predictions/predict.html)
        * [ Portable Predictions ](../predictions/port-pred.html)
      * [ Compliance ](../compliance/index.html) [ Compliance ](../compliance/index.html)
        * [ Model Compliance ](../compliance/compliance.html)
        * [ Template Builder for compliance reports ](../compliance/template-builder.html)
      * [ Comments ](../comments/index.html)
      * [ Bias and Fairness ](../bias/index.html) [ Bias and Fairness ](../bias/index.html)
        * [ Cross-Class Accuracy ](../bias/cross-acc.html)
        * [ Cross-Class Data Disparity ](../bias/cross-data.html)
        * [ Per-Class Bias ](../bias/per-class.html)
      * [ Other ](../other/index.html) [ Other ](../other/index.html)
        * [ Bias vs Accuracy ](../other/bias-tab.html)
        * [ Insights ](../other/analyze-insights.html)
        * [ Learning Curves ](../other/learn-curve.html)
        * [ Model Comparison ](../other/model-compare.html)
        * [ Speed vs Accuracy ](../other/speed.html)
    * [ Specialized workflows ](../../special-workflows/index.html) [ Specialized workflows ](../../special-workflows/index.html)
      * [ Bias and Fairness resources ](../../special-workflows/bias-resources.html)
      * [ Composable ML ](../../special-workflows/cml/index.html) [ Composable ML ](../../special-workflows/cml/index.html)
        * [ Composable ML overview ](../../special-workflows/cml/cml-overview.html)
        * [ Composable ML Quickstart ](../../special-workflows/cml/cml-quickstart.html)
        * [ Modify a blueprint ](../../special-workflows/cml/cml-blueprint-edit.html)
        * [ Create custom tasks ](../../special-workflows/cml/cml-custom-tasks.html)
        * [ Custom environments ](../../special-workflows/cml/cml-custom-env.html)
        * [ DRUM CLI tool ](../../special-workflows/cml/cml-drum.html)
        * [ Enable network access for custom tasks ](../../special-workflows/cml/custom-task-network-access.html)
      * [ Document AI ](../../special-workflows/doc-ai/index.html) [ Document AI ](../../special-workflows/doc-ai/index.html)
        * [ Document AI overview ](../../special-workflows/doc-ai/doc-ai-overview.html)
        * [ Document ingest and modeling ](../../special-workflows/doc-ai/doc-ai-ingest.html)
        * [ Document AI insights ](../../special-workflows/doc-ai/doc-ai-insights.html)
        * [ Predictions from documents ](../../special-workflows/doc-ai/doc-ai-predictions.html)
      * [ Location AI ](../../special-workflows/location-ai/index.html) [ Location AI ](../../special-workflows/location-ai/index.html)
        * [ Data ingest ](../../special-workflows/location-ai/lai-ingest.html)
        * [ Exploratory Spatial Data Analysis (ESDA) ](../../special-workflows/location-ai/lai-esda.html)
        * [ Modeling ](../../special-workflows/location-ai/lai-model.html)
        * [ Accuracy Over Space ](../../special-workflows/location-ai/lai-insights.html)
      * [ Unsupervised learning ](../../special-workflows/unsupervised/index.html) [ Unsupervised learning ](../../special-workflows/unsupervised/index.html)
        * [ Anomaly detection ](../../special-workflows/unsupervised/anomaly-detection.html)
        * [ Clustering ](../../special-workflows/unsupervised/clustering.html)
      * [ Visual AI ](../../special-workflows/visual-ai/index.html) [ Visual AI ](../../special-workflows/visual-ai/index.html)
        * [ Visual AI overview ](../../special-workflows/visual-ai/vai-overview.html)
        * [ Build Visual AI models ](../../special-workflows/visual-ai/vai-model.html)
        * [ Train-time image augmentation ](../../special-workflows/visual-ai/tti-augment/index.html) [ Train-time image augmentation ](../../special-workflows/visual-ai/tti-augment/index.html)
          * [ About augmented models ](../../special-workflows/visual-ai/tti-augment/ttia-introduction.html)
          * [ Transformations and lists ](../../special-workflows/visual-ai/tti-augment/ttia-lists.html)
          * [ Use case examples ](../../special-workflows/visual-ai/tti-augment/ttia-examples.html)
        * [ Model insights ](../../special-workflows/visual-ai/vai-insights.html)
        * [ Tune models ](../../special-workflows/visual-ai/vai-tuning.html)
        * [ Visual AI predictions ](../../special-workflows/visual-ai/vai-predictions.html)
      * [ Multilabel modeling ](../../special-workflows/multilabel.html)
      * [ Out-of-time validation modeling ](../../special-workflows/otv.html)
      * [ Text AI resources ](../../special-workflows/textai-resources.html)
    * [ Time-series modeling ](../../time/index.html) [ Time-series modeling ](../../time/index.html)
      * [ What is time-aware modeling? ](../../time/whatis-time.html)
      * [ Time series modeling ](../../time/ts-flow-overview.html)
      * [ Time series insights ](../../time/ts-leaderboard.html)
      * [ Time series predictions ](../../time/ts-predictions.html)
      * [ Time series portable predictions with prediction intervals ](../../time/ts-port-pred-intervals.html)
      * [ Multiseries modeling ](../../time/multiseries.html)
      * [ Clustering ](../../time/ts-clustering.html)
      * [ Segmented modeling ](../../time/ts-segmented.html)
      * [ Nowcasting ](../../time/nowcasting.html)
      * [ External prediction comparison ](../../time/cyob.html)
      * [ Batch predictions for TTS and LSTM models ](../../time/ts-tts-lstm-batch-pred.html)
      * [ Time series advanced modeling ](../../time/ts-adv-modeling/index.html) [ Time series advanced modeling ](../../time/ts-adv-modeling/index.html)
        * [ Time series advanced options ](../../time/ts-adv-modeling/ts-adv-opt.html)
        * [ Clustering advanced options ](../../time/ts-adv-modeling/ts-cluster-adv-opt.html)
        * [ Date/time partitioning advanced options ](../../time/ts-adv-modeling/ts-date-time.html)
        * [ Customizing time series projects ](../../time/ts-adv-modeling/ts-customization.html)
      * [ Time series modeling data ](../../time/ts-modeling-data/index.html) [ Time series modeling data ](../../time/ts-modeling-data/index.html)
        * [ Create the modeling dataset ](../../time/ts-modeling-data/ts-create-data.html)
        * [ Data prep for time series ](../../time/ts-modeling-data/ts-data-prep.html)
        * [ Restore features removed by reduction ](../../time/ts-modeling-data/restore-features.html)
    * [ AutoML preview features ](../../automl-preview/index.html) [ AutoML preview features ](../../automl-preview/index.html)
      * [ Quantile regression analysis ](../../automl-preview/quantile-reg.html)
      * [ Configure hyperparameters for custom tasks ](../../automl-preview/cml-hyperparam.html)
    * [ Modeling FAQ ](../../general-modeling-faq.html)
    * [ Value Tracker ](../../value-tracker.html)
    * [ Project control center ](../../manage-projects.html)
  * [ Predictions ](../../../predictions/index.html) [ Predictions ](../../../predictions/index.html)
    * [ Real-time scoring methods ](../../../predictions/realtime/index.html) [ Real-time scoring methods ](../../../predictions/realtime/index.html)
      * [ Prediction API snippets ](../../../predictions/realtime/code-py.html)
      * [ Qlik predictions ](../../../predictions/realtime/integration-code-snippets.html)
    * [ Batch prediction methods ](../../../predictions/batch/index.html) [ Batch prediction methods ](../../../predictions/batch/index.html)
      * [ Batch prediction UI ](../../../predictions/batch/batch-dep/index.html) [ Batch prediction UI ](../../../predictions/batch/batch-dep/index.html)
        * [ Make a one-time batch prediction ](../../../predictions/batch/batch-dep/batch-pred.html)
        * [ Schedule recurring batch prediction jobs ](../../../predictions/batch/batch-dep/batch-pred-jobs.html)
        * [ Manage prediction job definitions ](../../../predictions/batch/batch-dep/manage-pred-job-def.html)
        * [ Snowflake prediction job examples ](../../../predictions/batch/batch-dep/pred-job-examples-snowflake.html)
      * [ Prediction monitoring jobs ](../../../predictions/batch/pred-monitoring-jobs/index.html) [ Prediction monitoring jobs ](../../../predictions/batch/pred-monitoring-jobs/index.html)
        * [ Create monitoring jobs ](../../../predictions/batch/pred-monitoring-jobs/ui-monitoring-jobs.html)
        * [ Monitoring jobs API ](../../../predictions/batch/pred-monitoring-jobs/api-monitoring-jobs.html)
        * [ Manage monitoring job definitions ](../../../predictions/batch/pred-monitoring-jobs/manage-monitoring-job-def.html)
      * [ Manage batch jobs ](../../../predictions/batch/batch-jobs.html)
      * [ Batch prediction scripts ](../../../predictions/batch/cli-scripts.html)
    * [ Portable prediction methods ](../../../predictions/port-pred/index.html) [ Portable prediction methods ](../../../predictions/port-pred/index.html)
      * [ Scoring Code ](../../../predictions/port-pred/scoring-code/index.html) [ Scoring Code ](../../../predictions/port-pred/scoring-code/index.html)
        * [ Download Scoring Code from the Leaderboard ](../../../predictions/port-pred/scoring-code/sc-download-leaderboard.html)
        * [ Download Scoring Code from a deployment ](../../../predictions/port-pred/scoring-code/sc-download-deployment.html)
        * [ Download Scoring Code from the Leaderboard (Legacy) ](../../../predictions/port-pred/scoring-code/sc-download-legacy.html)
        * [ Scoring Code for time series projects ](../../../predictions/port-pred/scoring-code/sc-time-series.html)
        * [ Scoring at the command line ](../../../predictions/port-pred/scoring-code/scoring-cli.html)
        * [ Scoring Code usage examples ](../../../predictions/port-pred/scoring-code/quickstart-api.html)
        * [ JAR structure ](../../../predictions/port-pred/scoring-code/jar-package.html)
        * [ Generate Java models in an existing project ](../../../predictions/port-pred/scoring-code/build-verify.html)
        * [ Backward-compatible Java API ](../../../predictions/port-pred/scoring-code/java-back-compat.html)
        * [ Scoring Code JAR integrations ](../../../predictions/port-pred/scoring-code/sc-jar-integrations.html)
        * [ Android integration ](../../../predictions/port-pred/scoring-code/android.html)
      * [ Portable Prediction Server ](../../../predictions/port-pred/pps/index.html) [ Portable Prediction Server ](../../../predictions/port-pred/pps/index.html)
        * [ Portable Prediction Server configuration ](../../../predictions/port-pred/pps/portable-pps.html)
        * [ Portable Prediction Server running modes ](../../../predictions/port-pred/pps/pps-run-modes.html)
        * [ Portable batch predictions ](../../../predictions/port-pred/pps/portable-batch-predictions.html)
        * [ Custom model Portable Prediction Server ](../../../predictions/port-pred/pps/custom-pps.html)
      * [ DataRobot Prime (deprecated) ](../../../predictions/port-pred/prime/index.html)
    * [ Predictions testing ](../../../predictions/pred-test.html)
    * [ Predictions reference ](../../../predictions/pred-file-limits.html)
  * [ MLOps ](../../../mlops/index.html) [ MLOps ](../../../mlops/index.html)
    * [ Deployment ](../../../mlops/deployment/index.html) [ Deployment ](../../../mlops/deployment/index.html)
      * [ Deployment workflows ](../../../mlops/deployment/deploy-workflows/index.html) [ Deployment workflows ](../../../mlops/deployment/deploy-workflows/index.html)
        * [ DataRobot model in a DataRobot environment ](../../../mlops/deployment/deploy-workflows/dr-model-dr-env.html)
        * [ DataRobot model in a PPS ](../../../mlops/deployment/deploy-workflows/dr-model-pps-env.html)
        * [ Custom model in a DataRobot environment ](../../../mlops/deployment/deploy-workflows/cus-model-dr-env.html)
        * [ Custom model in a PPS ](../../../mlops/deployment/deploy-workflows/cus-model-pps-env.html)
        * [ Scoring Code in an external environment ](../../../mlops/deployment/deploy-workflows/ext-dr-model-ext-env.html)
        * [ Monitor an external model with the monitoring agent ](../../../mlops/deployment/deploy-workflows/ext-cus-model-ext-env.html)
      * [ Register models ](../../../mlops/deployment/registry/index.html) [ Register models ](../../../mlops/deployment/registry/index.html)
        * [ Model Registry ](../../../mlops/deployment/registry/reg-create.html)
        * [ Register DataRobot models ](../../../mlops/deployment/registry/dr-model-reg.html)
        * [ Register custom models ](../../../mlops/deployment/registry/reg-custom-models.html)
        * [ Register external models ](../../../mlops/deployment/registry/reg-external-models.html)
        * [ Deploy registered models ](../../../mlops/deployment/registry/reg-deploy.html)
        * [ View and manage registered models ](../../../mlops/deployment/registry/reg-action.html)
        * [ Generate model compliance documentation ](../../../mlops/deployment/registry/reg-compliance.html)
        * [ Extend compliance documentation with key values ](../../../mlops/deployment/registry/reg-key-values.html)
        * [ Custom jobs ](../../../mlops/deployment/registry/reg-custom-jobs.html)
        * [ Import model packages into MLOps ](../../../mlops/deployment/registry/reg-transfer.html)
        * [ Model logs for model packages (legacy) ](../../../mlops/deployment/registry/reg-model-pkg-logs.html)
      * [ Prepare custom models for deployment ](../../../mlops/deployment/custom-models/index.html) [ Prepare custom models for deployment ](../../../mlops/deployment/custom-models/index.html)
        * [ Custom Model Workshop ](../../../mlops/deployment/custom-models/custom-model-workshop/index.html) [ Custom Model Workshop ](../../../mlops/deployment/custom-models/custom-model-workshop/index.html)
          * [ Create custom inference models ](../../../mlops/deployment/custom-models/custom-model-workshop/custom-inf-model.html)
          * [ Manage custom model dependencies ](../../../mlops/deployment/custom-models/custom-model-workshop/custom-model-dependencies.html)
          * [ Manage custom model resources ](../../../mlops/deployment/custom-models/custom-model-workshop/custom-model-resource-mgmt.html)
          * [ Add custom model versions ](../../../mlops/deployment/custom-models/custom-model-workshop/custom-model-versions.html)
          * [ Add training data to a custom model ](../../../mlops/deployment/custom-models/custom-model-workshop/custom-model-training-data.html)
          * [ Add files from remote repos to custom models ](../../../mlops/deployment/custom-models/custom-model-workshop/custom-model-repos.html)
          * [ Test custom models ](../../../mlops/deployment/custom-models/custom-model-workshop/custom-model-test.html)
          * [ Manage custom models ](../../../mlops/deployment/custom-models/custom-model-workshop/custom-model-actions.html)
          * [ Register custom models ](../../../mlops/deployment/custom-models/custom-model-workshop/custom-model-reg.html)
          * [ Create custom model proxies for external models ](../../../mlops/deployment/custom-models/custom-model-workshop/ext-model-proxy.html)
          * [ GitHub Actions for custom models ](../../../mlops/deployment/custom-models/custom-model-workshop/custom-model-github-action.html)
        * [ Custom model environments ](../../../mlops/deployment/custom-models/custom-model-environments/index.html) [ Custom model environments ](../../../mlops/deployment/custom-models/custom-model-environments/index.html)
          * [ Drop-in environments ](../../../mlops/deployment/custom-models/custom-model-environments/drop-in-environments.html)
          * [ Custom environments ](../../../mlops/deployment/custom-models/custom-model-environments/custom-environments.html)
      * [ Prepare for external model deployment ](../../../mlops/deployment/ext-model-prep/index.html) [ Prepare for external model deployment ](../../../mlops/deployment/ext-model-prep/index.html)
        * [ Add external prediction environments ](../../../mlops/deployment/ext-model-prep/ext-pred-env.html)
        * [ Manage prediction environments ](../../../mlops/deployment/ext-model-prep/ext-pred-env-manage.html)
        * [ Register external models ](../../../mlops/deployment/ext-model-prep/ext-model-reg.html)
      * [ Manage prediction environments ](../../../mlops/deployment/prediction-env/index.html) [ Manage prediction environments ](../../../mlops/deployment/prediction-env/index.html)
        * [ Add DataRobot Serverless prediction environments ](../../../mlops/deployment/prediction-env/pred-env.html)
        * [ Add external prediction environments ](../../../mlops/deployment/prediction-env/ext-pred-env.html)
        * [ Manage prediction environments ](../../../mlops/deployment/prediction-env/pred-env-manage.html)
        * [ Deploy a model to a prediction environment ](../../../mlops/deployment/prediction-env/pred-env-deploy.html)
        * [ Prediction environment integrations ](../../../mlops/deployment/prediction-env/pred-env-integrations/index.html) [ Prediction environment integrations ](../../../mlops/deployment/prediction-env/pred-env-integrations/index.html)
          * [ Automated deployment and replacement of Scoring Code in AzureML ](../../../mlops/deployment/prediction-env/pred-env-integrations/azureml-sc-deploy-replace.html)
          * [ Automated deployment and replacement in Sagemaker ](../../../mlops/deployment/prediction-env/pred-env-integrations/sagemaker-cm-deploy-replace.html)
      * [ Deploy models ](../../../mlops/deployment/deploy-methods/index.html) [ Deploy models ](../../../mlops/deployment/deploy-methods/index.html)
        * [ Deploy DataRobot models ](../../../mlops/deployment/deploy-methods/deploy-model.html)
        * [ Deploy custom models ](../../../mlops/deployment/deploy-methods/deploy-custom-inf-model.html)
        * [ Deploy external models ](../../../mlops/deployment/deploy-methods/deploy-external-model.html)
        * [ Configure deployment settings ](../../../mlops/deployment/deploy-methods/add-deploy-info.html)
        * [ Add prediction data post-deployment ](../../../mlops/deployment/deploy-methods/add-prediction-data-post-deploy.html)
      * [ MLOps agents ](../../../mlops/deployment/mlops-agent/index.html) [ MLOps agents ](../../../mlops/deployment/mlops-agent/index.html)
        * [ Monitoring agent ](../../../mlops/deployment/mlops-agent/monitoring-agent/index.html) [ Monitoring agent ](../../../mlops/deployment/mlops-agent/monitoring-agent/index.html)
          * [ Installation and configuration ](../../../mlops/deployment/mlops-agent/monitoring-agent/agent.html)
          * [ Examples directory ](../../../mlops/deployment/mlops-agent/monitoring-agent/agent-ex.html)
          * [ Monitoring agent use cases ](../../../mlops/deployment/mlops-agent/monitoring-agent/agent-use.html)
          * [ Environment variables ](../../../mlops/deployment/mlops-agent/monitoring-agent/env-var.html)
          * [ Library and agent spooler configuration ](../../../mlops/deployment/mlops-agent/monitoring-agent/spooler.html)
          * [ Download Scoring Code ](../../../mlops/deployment/mlops-agent/monitoring-agent/agent-sc.html)
          * [ Monitoring external multiclass deployments ](../../../mlops/deployment/mlops-agent/monitoring-agent/agent-multi.html)
        * [ Management agent ](../../../mlops/deployment/mlops-agent/mgmt-agent/index.html) [ Management agent ](../../../mlops/deployment/mlops-agent/mgmt-agent/index.html)
          * [ Installation and configuration ](../../../mlops/deployment/mlops-agent/mgmt-agent/mgmt-agent-install.html)
          * [ Configure environment plugins ](../../../mlops/deployment/mlops-agent/mgmt-agent/mgmt-agent-plugins.html)
          * [ Install the management agent for Kubernetes ](../../../mlops/deployment/mlops-agent/mgmt-agent/mgmt-agent-kubernetes.html)
          * [ Management agent deployment status and events ](../../../mlops/deployment/mlops-agent/mgmt-agent/mgmt-agent-events-status.html)
          * [ Relaunch deployments ](../../../mlops/deployment/mlops-agent/mgmt-agent/mgmt-agent-relaunch.html)
          * [ Force delete deployments ](../../../mlops/deployment/mlops-agent/mgmt-agent/mgmt-agent-delete.html)
        * [ Agent event log ](../../../mlops/deployment/mlops-agent/agent-event-log.html)
    * [ Deployment settings ](../../../mlops/deployment-settings/index.html) [ Deployment settings ](../../../mlops/deployment-settings/index.html)
      * [ Set up service health monitoring ](../../../mlops/deployment-settings/service-health-settings.html)
      * [ Set up data drift monitoring ](../../../mlops/deployment-settings/data-drift-settings.html)
      * [ Set up accuracy monitoring ](../../../mlops/deployment-settings/accuracy-settings.html)
      * [ Set up fairness monitoring ](../../../mlops/deployment-settings/fairness-settings.html)
      * [ Set up humility rules ](../../../mlops/deployment-settings/humility-settings.html)
      * [ Configure retraining ](../../../mlops/deployment-settings/retraining-settings.html)
      * [ Configure challengers ](../../../mlops/deployment-settings/challengers-settings.html)
      * [ Configure predictions settings ](../../../mlops/deployment-settings/predictions-settings.html)
      * [ Enable data exploration ](../../../mlops/deployment-settings/data-exploration-settings.html)
      * [ Set up custom metrics monitoring ](../../../mlops/deployment-settings/custom-metrics-settings.html)
      * [ Set up timeliness tracking ](../../../mlops/deployment-settings/usage-settings.html)
    * [ Lifecycle management ](../../../mlops/manage-mlops/index.html) [ Lifecycle management ](../../../mlops/manage-mlops/index.html)
      * [ Deployment inventory ](../../../mlops/manage-mlops/deploy-inventory.html)
      * [ Manage deployments ](../../../mlops/manage-mlops/actions-menu.html)
      * [ Replace deployed models ](../../../mlops/manage-mlops/deploy-replace.html)
      * [ Manage Automated Retraining policies ](../../../mlops/manage-mlops/set-up-auto-retraining.html)
    * [ Performance monitoring ](../../../mlops/monitor/index.html) [ Performance monitoring ](../../../mlops/monitor/index.html)
      * [ Overview tab ](../../../mlops/monitor/dep-overview.html)
      * [ Accuracy tab ](../../../mlops/monitor/deploy-accuracy.html)
      * [ Data Drift tab ](../../../mlops/monitor/data-drift.html)
      * [ Service Health tab ](../../../mlops/monitor/service-health.html)
      * [ Challengers tab ](../../../mlops/monitor/challengers.html)
      * [ Usage tab ](../../../mlops/monitor/deploy-usage.html)
      * [ Data Exploration tab ](../../../mlops/monitor/data-exploration.html)
      * [ Custom Metrics tab ](../../../mlops/monitor/custom-metrics.html)
      * [ Segmented analysis ](../../../mlops/monitor/deploy-segment.html)
      * [ Batch monitoring ](../../../mlops/monitor/deploy-batch-monitor.html)
      * [ Generative model monitoring ](../../../mlops/monitor/generative-model-monitoring.html)
    * [ Governance ](../../../mlops/governance/index.html) [ Governance ](../../../mlops/governance/index.html)
      * [ Model deployment approval workflow ](../../../mlops/governance/dep-admin.html)
      * [ Governance lens ](../../../mlops/governance/gov-lens.html)
      * [ Notifications tab ](../../../mlops/governance/deploy-notifications.html)
      * [ Humility tab ](../../../mlops/governance/humble.html)
      * [ Fairness tab ](../../../mlops/governance/mlops-fairness.html)
      * [ Deployment reports ](../../../mlops/governance/deploy-reports.html)
    * [ MLOps preview features ](../../../mlops/mlops-preview/index.html) [ MLOps preview features ](../../../mlops/mlops-preview/index.html)
      * [ Service Health and Accuracy history ](../../../mlops/mlops-preview/pp-deploy-history.html)
      * [ Automated deployment and replacement of Scoring Code in Snowflake ](../../../mlops/mlops-preview/pp-snowflake-sc-deploy-replace.html)
      * [ Run the monitoring agent in DataRobot ](../../../mlops/mlops-preview/monitoring-agent-in-dr.html)
      * [ Feature cache for Feature Discovery deployments ](../../../mlops/mlops-preview/safer-ft-cache.html)
      * [ MLOps reporting for unstructured models ](../../../mlops/mlops-preview/mlops-unstructured-models.html)
    * [ MLOps FAQ ](../../../mlops/mlops-faq.html)
  * [ Notebooks ](../../../dr-notebooks/index.html) [ Notebooks ](../../../dr-notebooks/index.html)
    * [ Manage notebooks ](../../../dr-notebooks/manage-nb/index.html) [ Manage notebooks ](../../../dr-notebooks/manage-nb/index.html)
      * [ Add notebooks ](../../../dr-notebooks/manage-nb/dr-create-nb.html)
      * [ Notebook settings ](../../../dr-notebooks/manage-nb/dr-settings-nb.html)
      * [ Notebook versioning ](../../../dr-notebooks/manage-nb/dr-revise-nb.html)
    * [ Notebook coding experience ](../../../dr-notebooks/code-nb/index.html) [ Notebook coding experience ](../../../dr-notebooks/code-nb/index.html)
      * [ Environment management ](../../../dr-notebooks/code-nb/dr-env-nb.html)
      * [ Create and execute cells ](../../../dr-notebooks/code-nb/dr-cell-nb.html)
      * [ Cell actions ](../../../dr-notebooks/code-nb/dr-action-nb.html)
      * [ Code intelligence ](../../../dr-notebooks/code-nb/dr-code-int.html)
      * [ Notebook terminals ](../../../dr-notebooks/code-nb/dr-terminal-nb.html)
      * [ Azure OpenAI Service integration ](../../../dr-notebooks/code-nb/dr-openai-nb.html)
    * [ Notebook reference ](../../../dr-notebooks/dr-notebook-ref.html)
  * [ AI Apps ](../../../app-builder/index.html) [ AI Apps ](../../../app-builder/index.html)
    * [ Create applications ](../../../app-builder/create-app.html)
    * [ Manage applications ](../../../app-builder/current-app.html)
    * [ Edit no-code applications ](../../../app-builder/edit-apps/index.html) [ Edit no-code applications ](../../../app-builder/edit-apps/index.html)
      * [ Pages ](../../../app-builder/edit-apps/app-pages.html)
      * [ Widgets ](../../../app-builder/edit-apps/app-widgets.html)
      * [ What-if and Optimizer ](../../../app-builder/edit-apps/whatif-opt.html)
      * [ Settings ](../../../app-builder/edit-apps/app-settings.html)
    * [ Use no-code applications ](../../../app-builder/use-apps/index.html) [ Use no-code applications ](../../../app-builder/use-apps/index.html)
      * [ Make predictions ](../../../app-builder/use-apps/app-make-pred.html)
      * [ View prediction results ](../../../app-builder/use-apps/app-analyze-result.html)
    * [ Time series applications ](../../../app-builder/ts-app.html)
    * [ Custom apps ](../../../app-builder/custom-apps/index.html) [ Custom apps ](../../../app-builder/custom-apps/index.html)
      * [ Upload custom applications ](../../../app-builder/custom-apps/app-upload-custom.html)
      * [ Host custom applications ](../../../app-builder/custom-apps/custom-apps-hosting.html)
      * [ Manage custom applications ](../../../app-builder/custom-apps/manage-custom-apps.html)
    * [ AI App reference ](../../../app-builder/reference/index.html) [ AI App reference ](../../../app-builder/reference/index.html)
      * [ Default widgets ](../../../app-builder/reference/default-widgets.html)
      * [ Optional widgets ](../../../app-builder/reference/optional-widgets.html)
    * [ AI App preview features ](../../../app-builder/app-preview/index.html) [ AI App preview features ](../../../app-builder/app-preview/index.html)
      * [ Prefill application templates ](../../../app-builder/app-preview/app-prefill.html)
      * [ Feature Discovery support in No-Code AI Apps ](../../../app-builder/app-preview/app-ft-cache.html)
  * [ Integrations ](../../../integrations/index.html) [ Integrations ](../../../integrations/index.html)
    * [ AWS ](../../../integrations/aws/index.html) [ AWS ](../../../integrations/aws/index.html)
      * [ Import data from AWS S3 ](../../../integrations/aws/import-from-aws-s3.html)
      * [ Deploy models on AWS EKS ](../../../integrations/aws/deploy-dr-models-on-aws.html)
      * [ Path-based routing to PPS ](../../../integrations/aws/path-based-routing-to-pps-on-aws.html)
      * [ Score Snowflake data on AWS EMR Spark ](../../../integrations/aws/score-snowflake-aws-emr-spark.html)
      * [ Ingest data with AWS Athena ](../../../integrations/aws/ingest-athena.html)
      * [ AWS Lambda ](../../../integrations/aws/lambda/index.html) [ AWS Lambda ](../../../integrations/aws/lambda/index.html)
        * [ AWS Lambda reporting to MLOps ](../../../integrations/aws/lambda/aws-lambda-reporting-to-mlops.html)
        * [ Use DataRobot Prime models with AWS Lambda ](../../../integrations/aws/lambda/prime-lambda.html)
        * [ Use Scoring Code with AWS Lambda ](../../../integrations/aws/lambda/sc-lambda.html)
      * [ Amazon SageMaker ](../../../integrations/aws/sagemaker/index.html) [ Amazon SageMaker ](../../../integrations/aws/sagemaker/index.html)
        * [ Deploy models on SageMaker ](../../../integrations/aws/sagemaker/sagemaker-deploy.html)
        * [ Use Scoring Code with AWS SageMaker ](../../../integrations/aws/sagemaker/sc-sagemaker.html)
    * [ Azure ](../../../integrations/azure/index.html) [ Azure ](../../../integrations/azure/index.html)
      * [ Run Batch Prediction jobs from Azure Blob Storage ](../../../integrations/azure/azure-blob-storage-batch-pred.html)
      * [ Deploy and monitor DataRobot models in Azure Kubernetes Service ](../../../integrations/azure/aks-deploy-and-monitor.html)
      * [ Deploy and monitor Spark models with DataRobot MLOps ](../../../integrations/azure/spark-deploy-and-monitor.html)
      * [ Deploy and monitor ML.NET models with DataRobot MLOps ](../../../integrations/azure/mlnet-deploy-and-monitor.html)
      * [ Use Scoring Code with Azure ML ](../../../integrations/azure/sc-azureml.html)
    * [ Google ](../../../integrations/google/index.html) [ Google ](../../../integrations/google/index.html)
      * [ Deploy and monitor models on GCP ](../../../integrations/google/google-cloud-platform.html)
      * [ Deploy the MLOps agent on GKE ](../../../integrations/google/mlops-agent-with-gke.html)
    * [ Snowflake ](../../../integrations/snowflake/index.html) [ Snowflake ](../../../integrations/snowflake/index.html)
      * [ Data ingest and project creation ](../../../integrations/snowflake/sf-project-creation.html)
      * [ Real-time predictions ](../../../integrations/snowflake/sf-client-scoring.html)
      * [ Server-side model scoring ](../../../integrations/snowflake/sf-server-scoring.html)
      * [ Snowflake external functions and streams ](../../../integrations/snowflake/sf-function-streams.html)
      * [ Generate Snowflake UDF Scoring Code ](../../../integrations/snowflake/snowflake-sc.html)

[For Self-Managed AI Platform users running v11.1, see the on-premise platform
documentation __](/11.1/en/docs/index.html)

Feature Effects

  * Display options 
    * Sort options 
    * Set the number of bins 
    * Select the partition fold 
    * Select the class (multiclass only) 
    * Export 
    * More options 
  * List of features 
  * Feature Effects results 
    * Target range (Y-axis) 
    * Feature values (X-axis) 
      * For numeric features 
      * Predicted/actual logic 
      * Partial dependence logic 
      * Chart-specific logic 
      * For categorical features 
    * Feature value tooltip 
    * Feature value count 
    * Display controls 
  * More info... 
    * Average value calculations 
    * Interpret the displays 
      * Training data as the viewing subset 
    * Partial dependence calculations 
    * Data selection for time-aware projects 
      * Calculate backtests 
      * Set the partition fold 
      * Interpret days as numerics 
    * Binning and top values 
    * How Exposure changes output 
    * How Weight changes output 

[Modeling](../../index.html "Modeling") > [Model insights](../index.html
"Model insights") > [Understand](index.html "Understand") > Feature Effects

# Feature Effects¶

**Feature Effects** shows the effect of changes in the value of each feature
on the model’s predictions. It displays a graph depicting how a model
"understands" the relationship between each feature and the target, with the
features sorted by [**Feature Impact**](feature-impact.html). The insight is
communicated in terms of partial dependence, which illustrates how a change in
a feature's value, while keeping all other features as they were, impacts a
model's predictions. Literally, "what is the feature's effect, how is _this_
model using _this_ feature?" To compare the model evaluation methods side by
side:

  * **Feature Impact** conveys the relative impact of each feature on a specific model.
  * **Feature Effects** (with partial dependence) conveys how changes to the value of each feature change model predictions.

Clicking **Compute Feature Effects** causes DataRobot to first compute
**Feature Impact** (if not already computed for the model) on all data. If you
change the [data slice](../../../reference/pred-ai-ref/sliced-insights.html)
for **Feature Effects** or the [quick-compute](feature-impact.html#quick-
compute) setting for **Feature Impact** , **Feature Effects** will still use
the original **Feature Impact** settings. In other words, DataRobot does not
change the basis of (recalculate) **Feature Effects** visualizations that have
already been calculated. If you subsequently change the **Feature Impact**
quick-compute setting, all new calculations will use the new **Feature
Impact** calculations.

See below for more information on how DataRobot calculates values, explanation
of tips for using the displays, and how Exposure and Weight change the output.

[![](../../../images/feature-effect-callout.png)](../../../images/feature-
effect-callout.png)

The completed result looks similar to the following, with three main screen
components:

  * Display options
  * List of top features
  * Chart of results

## Display options¶

[![](../../../images/feature-effects-display-
opt.png)](../../../images/feature-effects-display-opt.png)

The following table describes the display control options for **Feature
Effects** :

| Element | Description  
---|---|---  
1 | Sort by | Provides controls for sorting.  
2 | Bins | For qualifying feature types, sets the binning resolution for the feature value count display.  
3 | Data Selection | Controls which partition fold is used as 1) the basis of the Predicted and Actual values and 2) the sample used for the computation of partial dependence. Options for OTV projects differ slightly.  
4 | [Data slice](../../../reference/pred-ai-ref/sliced-insights.html) | _Binary classification and regression only_. Selects the filter that defines the subpopulation to display within the insight.  
Not shown | Class | _Multiclass only_. Provides controls to display graphed results for a particular class within the target feature.  
5 | **More** | Controls whether to display missing values and changes the Y-axis scale.  
6 | **Export** | Provides options for downloading data.  
  
Tip

This visualization supports sliced insights. Slices allow you to define a
user-configured subpopulation of a model's data based on feature values, which
helps to better understand how the model performs on different segments of
data. See the full [documentation](../../../reference/pred-ai-ref/sliced-
insights.html) for more information.

### Sort options¶

The **Sort by** dropdown provides sorting options for plot data. For
categorical features, you can sort alphabetically, by frequency, or by size of
the effect (partial dependence). For numeric features, sort is always numeric.

### Set the number of bins¶

The **Bins** setting allows you to set the binning resolution for the display.
This option is only available when the selected feature is a numeric or
continuous variable; it is not available for categorical features or numeric
features with low unique values. Use the feature value tooltip to view bin
statistics.

### Select the partition fold¶

You can set the partition fold used for predicted, actual, and partial
dependence value plotting with the **Data Selection** dropdown—Training,
Validation, and, if unlocked, Holdout. While it may not be immediately
obvious, there are good reasons to investigate the training dataset results.

[![](../../../images/ff-fe-data-selection.png)](../../../images/ff-fe-data-
selection.png)

When you select a partition fold, that selection applies to all three display
controls, whether or not the control is checked. Note, however, that while
performed on the same partition fold, the partial dependence calculation uses
a different range of the data.

Note that **Data Selection** options differ depending on whether or not you
are investigating a time-aware project:

_For non-time-aware projects:_ In all cases you can select the Training or
Validation set; if you have unlocked holdout, you also have an option to
select the Holdout partition.

_For time-aware projects:_ For time-aware projects, you can select Training,
Validation, and/or Holdout (if available) as well as a specific backtest. See
the section on time-aware Data Selection settings for details.

### Select the class (multiclass only)¶

In a multiclass project, you can additionally set the display to chart per-
class results for each feature in your dataset.

[![](../../../images/fe-multiclass-1.png)](../../../images/fe-
multiclass-1.png)

By default, DataRobot calculates effects for the top 10 features. To view per-
class results for features ranked lower than 10, click **Compute** next to the
feature name:

[![](../../../images/fe-multiclass-2.png)](../../../images/fe-
multiclass-2.png)

### Export¶

The **Export** option allows you to [export](../../../reference/pred-ai-
ref/export-results.html) the graphs and data associated with the model's
details and for individual features. If you choose to export a ZIP file, you
will get all of the chart images and the CSV files for partial dependence and
predicted vs actual data.

### More options¶

The **Feature Effects** insight provides tools for re-displaying the chart to
help you focus on areas of importance.

Note

This option is only available when one of the following conditions is met:
there are missing values in the dataset, the chart's access is scalable, the
project is binary classification.

Click the gear setting to view the choices:

[![](../../../images/feature-effect-more.png)](../../../images/feature-effect-
more.png)

Check or uncheck the following boxes to activate:

  * **Show Missing Values** : Shows or hides the effect of missing values. This selection is available for numeric features only. The bin corresponding to missing values is labeled as **=Missing=**.

  * **Auto-scale Y-axis** : Resets the Y-axis range, which is then used to chart the actual data, the prediction, and the partial dependence values. When checked (the default), the values on the axis span the highest and lowest values of the target feature. When unchecked, the scale spans the entire eligible range (for example, 0 through 1 for binary projects).

  * **Log X-Axis** : Toggles between the different X-axis representations. This selection is available for highly skewed (distribution where one of tail is longer than the other) with numeric features having values greater than zero.

## List of features¶

[![](../../../images/feature-effects-list.png)](../../../images/feature-
effects-list.png)

The following table describes the feature list output of the **Feature
Effects** display:

| Element | Description  
---|---|---  
1 | Search for features | Lists of the top features that have more than zero-influence on the model, based on the Feature Impact (**Feature Effects**) score.  
2 | Score | Reports the relevance to the target feature. This is the value displayed in the [**Feature Impact**](feature-impact.html) display.  
  
To the left of the graph, DataRobot displays a list of the top 500 predictors.
Use the arrow keys or scroll bar to scroll through features, or the search
field to find by name. If all the sample rows are empty for a given feature,
the feature is not available in the list. Selecting a feature in the list
updates the display to reflect results for that feature.

Each feature in the list is accompanied by its [feature impact](feature-
impact.html) score. Feature impact measures, for each of the top 500 features,
the importance of one feature on the target prediction. It is estimated by
calculating the prediction difference before and after shuffling the selected
rows of one feature (while leaving other columns unchanged). DataRobot
normalizes the scores so that the value of the most important column is 1
(100%). A score of 0% indicates that there was no calculated relationship.

## Feature Effects results¶

[![](../../../images/feature-effects-chart.png)](../../../images/feature-
effects-chart.png)

| Element | Description  
---|---|---  
1 | Target range | Displays the value range for the target; the Y-axis values can be adjusted with the scaling option.  
2 | Feature values | Displays individual values of the selected feature.  
3 | Feature values tooltip | Provides summary information for a feature's binned values.  
4 | Feature value count | Sets, for the selected feature, the feature distribution for the selected partition fold.  
5 | Display controls | Sets filters that control the values plotted in the display (partial dependence, predicted, and/or actual).  
  
### Target range (Y-axis)¶

The Y-axis represents the value range for the target variable. For binary
classification and regression problems, this is a value between 0 and 1. For
non-binary projects, the axis displays from min to max values. Note that you
can use the scaling feature to change the Y-axis and bring greater focus to
the display.

### Feature values (X-axis)¶

The X-axis displays the values found for the feature selected in the list of
features. The selected sort order controls how the values are displayed. See
the section on partial dependence calculations for more information.

#### For numeric features¶

The logic for a numeric feature depends on whether you are displaying
predicted/actual or partial dependence.

#### Predicted/actual logic¶

  * If the value count in the selected partition fold is greater than 20, DataRobot bins the values based on their distribution in the fold and computes Predicted and Actual for each bin.

  * If the value count is 20 or less, DataRobot plots Predicted/Actuals for the top values present in the fold selected.

#### Partial dependence logic¶

  * If the value count of the feature in the entire dataset is greater than 99, DataRobot computes partial dependence on the percentiles of the distribution of the feature in the entire dataset.

  * If the value count is 99 or less, DataRobot computes partial dependence on all values in the dataset (excluding outliers).

#### Chart-specific logic¶

Partial dependence feature values are derived from the percentiles of the
distribution of the feature across the entire dataset. The X-axis may
additionally display a `==Missing==` bin, which contains the effect of missing
values. Partial dependence calculation always includes "missing values," even
if the feature is not missing throughout dataset. The display shows what
_would be_ the average predictions if the feature were missing—DataRobot
doesn't need the feature to actually be missing, it's just a "what if."

#### For categorical features¶

For categorical, the X-axis displays the 25 most frequent values for
predicted, actual, and partial dependence in the selected partition fold. The
categories can include, as applicable:

  * `=All Other=`: For categorical features, a single bin containing all values other than the 25 most frequent values. No partial dependence is computed for `=All Other=`. DataRobot uses one-hot encoding and ordinal encoding preprocessing tasks to automatically group low-frequency levels.

For both tasks you can use the `min_support` [advance tuning](../evaluate/adv-
tuning.html) parameter to group low-frequency values. By default, DataRobot
uses a value of 10 for the one-hot encoder and 5 for the ordinal encoder. In
other words, any category that has fewer than 10 levels (one-hot encoder) or 5
(ordinal encoder) is combined into 1 group.

  * `==Missing==`: A single bin containing all rows with missing feature values (that is, NaN as the value of one of the features).

  * `==Other Unseen==`: A single bin containing all values that were not present in the Training set. No partial dependence is computed for `=Other Unseen=`. See the explanation below for more information.

[![](../../../images/feature-eff-fvalue-1.png)](../../../images/feature-eff-
fvalue-1.png)

### Feature value tooltip¶

For each bin, to display a feature's calculated values and row count, hover in
the display area above the bin. For example, this tooltip:

[![](../../../images/feature-eff-hover.png)](../../../images/feature-eff-
hover.png)

Indicates:

For the feature `number diagnoses` when the value is `7`, the partial
dependence average was (roughly) `0.407` and the actual values average was
`0.432`. These averages were calculated from `201` rows in the dataset (in
which the number of diagnoses was seven). Select the **Predicted** label to
see the predicted average.

### Feature value count¶

The bar graph below the X-axis provides a visual indicator, for the selected
feature, of each of the feature's value frequencies. The bars are mapped to
the feature values listed above them, and so changing the sort order also
changes the bar display. This is the same information as that presented in the
[**Frequent Values**](../../../data/analyze-data/analyze-frequent-values.html)
chart on the **Data** page. For qualifying feature types, you can use the
**Bins** dropdown to set the number of bars (determine the binning).

### Display controls¶

Use the display control links to set the display of plotted data. Actual
values are represented by open orange circles, predicted valued by blue
crosses, and partial dependence points by solid yellow circles. In this way,
points lie on top without blocking view of each other. Click or unclick the
label in the legend to focus on a particular aspect of the display. See below
for information on how DataRobot calculates and displays the values.

## More info...¶

The following sections describe:

  * How DataRobot calculates average values and partial dependence
  * Interpreting the displays
  * Time-aware data selection
  * Understanding unseen values
  * How Exposure and Weight change output

### Average value calculations¶

For the predicted and actual values in the display, DataRobot plots the
average values. The following simple example explains the calculation.

In the following dataset, Feature A has two possible values—1 and 2:

Feature A | Feature B | Target  
---|---|---  
1 | 2 | 4  
2 | 3 | 5  
1 | 2 | 6  
2 | 4 | 8  
1 | 3 | 1  
2 | 2 | 2  
  
In this fictitious dataset, the X axis would show two values: 1 and 2. When
target value A=1, DataRobot calculates the average as 4+6+1 / 3. When A=2, the
average is 5+8+2 / 3. So the actual and predicted points on the graph show the
average target for each aggregated feature value.

Specifically:

  * For numeric features, DataRobot generates bins based on the feature domain. For example, for the feature `Age` with a range of 16-101, bins (the user selects the number) would be based on that range.
  * For categorical features, for example `Gender`, DataRobot generates bins based on the top unique values (perhaps 3 bins—`M`, `F`, `N/A`).

DataRobot then calculates the average values of prediction in each bin and the
average of the actual values of each bin.

### Interpret the displays¶

In the **Feature Effects** display, categorical features are represented as
points; numerical features are represented as connected points. This is
because each numerical value can be seen in relation to the other values,
while categorical features are not linearly related. A dotted line indicates
that there were not enough values to plot.

Note

If you are using the [Exposure](../../build-models/adv-
opt/additional.html#set-exposure) parameter feature available from the
**Advanced options** tab, line calculations differ.

Consider the following **Feature Effects** display:

[![](../../../images/feature-effects-lines.png)](../../../images/feature-
effects-lines.png)

The orange open circles depict, for the selected feature, the _average target
value_ for the aggregated **number_diagnoses** feature values. In other words,
when the target is **readmitted** and the selected feature is
**number_diagnoses** , a patient with two diagnoses has, on average, a roughly
23% chance of being readmitted. Patients with three diagnoses have, on
average, a roughly 35% chance of readmittance.

The blue crosses depict, for the selected feature, the _average prediction_
for a specific value. From the graph you can see that DataRobot averaged the
predicted feature values and calculated a 25% chance of readmittance when
**number_diagnoses** is two. Comparing the actual and predicted lines can
identify segments where model predictions differ from observed data. This
typically occurs when the segment size is small. In those cases, for example,
some models may predict closer to the overall average.

The yellow **Partial Dependence** line depicts the marginal effect of a
feature on the target variable after accounting for the average effects of all
other predictive features. It indicates how, holding all other variables
_except_ the feature of interest as they were, the value of this feature
affects your prediction. The value of the feature of interest is then
reassigned to each possible value, calculating the average predictions for the
sample at each setting. (From the simple example above, DataRobot calculates
the average results when all 1000 rows use value 1 and then again when all
1000 rows use value 2.) These values help determine how the value of each
feature affects the target. The shape of the yellow line "describes" the
model’s view of the marginal relationship between the selected feature and the
target. See the discussion of partial dependence calculation for more
information.

Tips for using the displays:

  * To evaluate model accuracy, uncheck the partial dependence box. You are left with a visual indicator that charts actual values against the model's predicted values.

  * To understand partial dependence, uncheck the actual and predicted boxes. Set the sort order to **Effect Size**. Consider the partial dependence line carefully. Isolating the effect of important features can be very useful in optimizing outcomes in business scenarios.

  * If there are not enough observations in the sample at a particular level, the partial dependency computation may be missing for a specific feature value.

  * A dashed instead of solid predicted (blue) and actual (orange) line indicates that there are no rows in the bins created at the point in the chart.

  * For numeric variables, if there are more than 18 values, DataRobot calculates partial dependence on values derived from the percentiles of the distribution of the feature across the entire dataset. As a result, the value is not displayed in the hover tooltip.

#### Training data as the viewing subset¶

Viewing **Feature Effect** for training data provides a few benefits. It helps
to determine how well a trained model fits the data it used for training. It
also lets you compare the difference between seen and unseen data in the model
performance. In other words, viewing the training results is a way to check
the model against known values. If the predicted vs the actual results from
the training set are weak, it is a sign that the model is not appropriately
selected for the data.

When considering partial dependence, using training data means the values are
calculated based on training samples and compared against the maximum possible
feature domain. It provides the option to check the relationship between a
single feature (by removing marginal effects from other features) and the
target across the entire range of the data. For example, suppose the
validation set covers January through June but you want to see partial
dependence in December. Without that month's data in validation, you wouldn't
be able to. However, by setting the data selection subset to **Training** ,
you could see the effect.

### Partial dependence calculations¶

Predicted/actual and partial dependence values are computed very differently
for continuous data. The calculations that bin the data for predicted/actual
(for example, `(1-40], (40-50]...`) are created to result in sufficient
material for computing averages. DataRobot then bins the values based on the
distribution of the feature for the selected partition fold.

Partial dependence, on the other hand, uses single values (for example, `1`,
`5`, `10`, `20`, `40`, `42`, `45...`) that are percentiles of the distribution
of the feature across the entire dataset. It uses up to 1000-row samples to
determine the scale of the curve. To make the scale comparable with
predicted/actual, the 1000 samples are drawn from the data of the selected
fold. In other words, partial dependence is _calculated_ for the maximum
possible range of values from the entire dataset but scaled based on the
**Data Selection** fold setting.

For example, consider a feature `year`. For partial dependence, DataRobot
computes values based on all the years in the data. For predicted/actual,
computation is based on the years in the selected fold. If the dataset dates
range from 2001-01-01 to 2010-01-01, DataRobot uses that span for partial
dependence calculations. Predicted/actual calculations, in contrast, contain
only the data from the corresponding, selected fold/backtest. You can see this
difference when viewing all three control displays for a selected fold:

[![](../../../images/fe-fold-pd-display.png)](../../../images/fe-fold-pd-
display.png)

Deep dive: Partial dependence calculations

The partial dependence plot shows the marginal effect a feature has on the
predicted outcome of a machine learning model—or how the prediction varies if
we just change one feature and keep everything else constant. The following
calculation illustrates this for one feature, `X1`, on a sample of 1000
records of training data.

Assume that `X1` has 5 different values (like 0, 5, 10, 15, 20). For all 1000
records, DataRobot creates artificial datapoints by keeping all features
constant except the feature `X1`, which translates to 5,000 records (each row
duplicated 5 times with one value of the different levels of X1). Then it
makes predictions for all 5,000 records and averages the predictions for each
level of `X1`. This average prediction now corresponds to the marginal effect
of feature `X1`, as displayed on the partial dependence plot.

If there are 10 features, and each feature has 5 different values in a
training dataset of 10K records, creating the marginal effect using all the
data would require making predictions using 500k records (computationally
expensive). Because it can obtain similar results for less "cost," DataRobot
only uses a representative sample of the data to calculate partial dependence.

Why is the partial dependence plot short compared to the range of the actual
data?

Note that because calculations are based on 1000 rows, it is quite possible
that values from the tail ends of the distribution aren't captured by the
sample. Also, the selected partition (holdout or validation) may not contain
the full range of data, which can be especially true in the case of OTV or
group partitioning. Finally, **Feature Effects** uses its own outlier logic to
improve the clarity of the chart. If in the given sample, 4% of the tail ends
represent more than 20% of X-axis, DataRobot limits the calculations to a
range between the 2-98 percentiles.

### Data selection for time-aware projects¶

When working with time-aware projects, **Data Selection** dropdown works a bit
differently because of the backtests. Select the **Feature Effects** tab for
your model of interest. If you haven't already computed values for the tab,
you are prompted to compute for **Backtest 1** (Validation).

Note

If the model you are viewing uses start and end dates (common for the
recommended model), backtest selection is not available.

When DataRobot completes the calculations, the insight displays with the
following **Data Selection** setting:

[![](../../../images/ts-data-selection-1.png)](../../../images/ts-data-
selection-1.png)

#### Calculate backtests¶

The results of clicking on the backtest name depend on whether backtesting has
been run for the model. DataRobot automatically computes backtests for the
highest scoring models; for lower-scoring models, you must select **Run** from
the Leaderboard to initiate backtesting:

[![](../../../images/ts-data-selection-2.png)](../../../images/ts-data-
selection-2.png)

For comparison, the following illustrates when backtests have not been run and
when they have:

[![](../../../images/ts-data-selection-3.png)](../../../images/ts-data-
selection-3.png)

When calculations are complete, you must then run **Feature Effect**
calculations for each backtest you want to display, as well as for the Holdout
fold, if applicable. From the dropdown, click a backtest that is not yet
computed and DataRobot provides a button to initiate calculations.

#### Set the partition fold¶

Once backtest calculations are complete for your needs, use the **Data
Selection** control to choose the backtest and partition for display. The
available partition folds are dependent on the backtest:

Options are:

  * For numbered backtests: Validation and Training for each calculated backtest
  * For the Holdout Fold: Holdout and Training

Click the down arrow to open the dialog and select a partition:

[![](../../../images/ts-data-selection-4.png)](../../../images/ts-data-
selection-4.png)

Or, click the right and left arrows to move through the options for the
currently selected partition—Validation or Training—plus Holdout. If you move
to an option that has yet to be computed, DataRobot provides a button to
initiate the calculation:

[![](../../../images/ts-data-selection-5.png)](../../../images/ts-data-
selection-5.png)

#### Interpret days as numerics¶

When interpreting the results of a Feature Effects chart within a time series
project, the derived `Datetime (Day of Week) (actual)` feature correlates a
day to a numeric. Specifically, Monday is always `0` in a Day of Week feature
(Tuesday is `1`, etc.). DataRobot uses the Python [time access and conversion
module](https://docs.python.org/3/library/time.html) (`tm_wday`) for this
time-related function.

### Binning and top values¶

By default, DataRobot calculates the top features listed in **Feature
Effects** using the training dataset. For categorical feature values,
displayed as discrete points on the X-axis, the segmentation is affected if
you select a different data source. To understand the segmentation, consider
the illustration below and the table describing the segments:

[![](../../../images/ff-fe-bins.png)](../../../images/ff-fe-bins.png)

As illustrated in chart | Label in chart | Description  
---|---|---  
Top-_N_ values | <_feature_value_ > | Values for the selected feature, with a maximum of 20 values. For any feature with more than 10 values, DataRobot further filters the results, as described in the example below.  
Other values | `==All Other==` | A single bin containing all values other than the Top-_N_ most frequent values.  
Missing values | `==Missing==` | A single bin containing all records with missing feature values (that is, NaN as the value of one of the features).  
Unseen values | <_feature_value_ > `(Unseen)` | Categorical feature values that were not "seen" in the Training set but qualified as Top-_N_ in Validation and/or Holdout.  
Unseen values | `==Other Unseen==` | Categorical feature values that were not "seen" in the Training set and did not qualify as Top-_N_ in Validation and/or Holdout.  
  
A simple example to explain Top-_N_ :

Consider a dataset with categorical feature `Population` and a world
population of 100. DataRobot calculates Top-_N_ as follows:

  1. Ranks countries by their population.
  2. Selects up to the top-20 countries with the highest population.
  3. In cases with more than 10 values, DataRobot further filters the results so that accumulative frequency is >95%. In other words, DataRobot displays in the X-axis those countries where their accumulated population hits 95% of the world population.

A simple example to explain _Unseen_ :

Consider a dataset with the categorical feature `Letters`. The complete list
of values for `Letters` is A, B, C, D, E, F, G, H. After filtering, DataRobot
determines that Top-_N_ equals three values. Note that, because the feature is
categorical, there is no `Missing` bin.

Fold/set | Values found | Top-3 values | X-axis values  
---|---|---|---  
Training set | A, B, C, D | A, B, C | A, B, C, `=All Other=`  
Validation set | B, C, F, G+ | B, C, F* | B, C, F (unseen), `=All Other=`, `Other Unseen`+  
Holdout set | C, E, F, H+ | C, E _, F_ | C, E (unseen), F (unseen), `=All Other=`, `Other Unseen`+  
  
* A new value in the top 3 but not present in the Training set, flagged as `Unseen`

+ A new value not present in Training or in top-3, flagged as `Other Unseen`

### How Exposure changes output¶

[![](../../../images/feature-effect-exposure.png)](../../../images/feature-
effect-exposure.png)

If you used the [Exposure](../../build-models/adv-opt/additional.html#set-
exposure) parameter when building models for the project, the **Feature
Effects** tab displays the graph adjusted to exposure. In this case:

  * The orange line depicts the _sum of the target divided by the sum of exposure_ for a specific value. The label and tooltip display _Sum of Actual/Sum of Exposure_ , which indicates that exposure was used during model building.

  * The blue line depicts the _sum of predictions divided by the sum of exposure_ and the legend label displays _Sum of Predicted/Sum of Exposure_.

  * The marginal effect depicted in the yellow _partial dependence_ is divided by the sum of exposure of the 1000-row sample. This adjustment is useful in insurance, for example, to understand the relationship between annualized cost of a policy and the predictors. The label tooltip displays _Average partial dependency adjusted by exposure_.

### How Weight changes output¶

If you set the **Weight** parameter for the project, DataRobot weights the
average and sum operations as described above.

Back to top

